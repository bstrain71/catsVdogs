{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Strain Keras CNN Dog or Cat Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bstrain71/catsVdogs/blob/master/Strain_Keras_CNN_Dog_or_Cat_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5bUhE3OaMdt",
        "colab_type": "text"
      },
      "source": [
        "Modified from: https://www.kaggle.com/uysimty/keras-cnn-dog-or-cat-classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0LQlPLUZrsv",
        "colab_type": "text"
      },
      "source": [
        "This Kernel for someone want to deep dive into image classification. I use CNN for classification model. If you found this Kernel helpful please up vote it. If you have some feedback and question don't forget to comment below. \n",
        "\n",
        "I have simplier model with \n",
        "* https://www.kaggle.com/uysimty/get-start-image-classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "fe76d1d1ded592430e7548feacfa38dc42f085d9",
        "id": "S3jPGDLfZrs0",
        "colab_type": "text"
      },
      "source": [
        "# Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "UNFlG8dZZrs5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "d8ccce15-142b-4a29-c25e-94f8ef3133fb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "print(os.listdir(\"../input\"))\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-81e205a9445e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHVOiqJDZrtC",
        "colab_type": "text"
      },
      "source": [
        "# Define Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "turT2Lg7ZrtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FAST_RUN = False\n",
        "IMAGE_WIDTH=128\n",
        "IMAGE_HEIGHT=128\n",
        "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "7335a579cc0268fba5d34d6f7558f33c187eedb3",
        "id": "Uucl5mKbZrtL",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Traning Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM6Zs7_Zb0R6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "42646ee3-9c7b-4da4-f990-9cb297d4bf21"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-09 04:32:30--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.127.128, 2a00:1450:4013:c05::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.127.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "\r          /tmp/cats   0%[                    ]       0  --.-KB/s               \r         /tmp/cats_  13%[=>                  ]   8.84M  44.2MB/s               \r        /tmp/cats_a  24%[===>                ]  16.01M  32.1MB/s               \r       /tmp/cats_an  73%[=============>      ]  48.01M  60.9MB/s               \r/tmp/cats_and_dogs_ 100%[===================>]  65.43M  73.0MB/s    in 0.9s    \n",
            "\n",
            "2019-11-09 04:32:32 (73.0 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsKsPUGGcET1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Rl_zs-d6jI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "e-fOn16oZrtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dog_filenames = os.listdir(\"/tmp/cats_and_dogs_filtered/train/dogs\")\n",
        "cat_filenames = os.listdir(\"/tmp/cats_and_dogs_filtered/train/cats\")\n",
        "categories = []\n",
        "for filename in dog_filenames:\n",
        "    category = filename.split('.')[0]\n",
        "    if category == 'dog':\n",
        "        categories.append(1)\n",
        "    else:\n",
        "        categories.append(0)\n",
        "\n",
        "for filename in cat_filenames:\n",
        "  category = filename.split('.')[0]\n",
        "  if category == 'dog':\n",
        "      categories.append(1)\n",
        "  else:\n",
        "      categories.append(0)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'filename': dog_filenames + cat_filenames,\n",
        "    'category': categories\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXHJ-3T4eDFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "4efae08c-7f74-4dce-b242-e32f81c2060f"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "915bb9ba7063ab4d5c07c542419ae119003a5f98",
        "id": "sfoTRh5bZrtT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "03c190b1-5ea7-4419-aa7a-044276b4569c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dog.142.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>dog.638.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dog.907.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dog.485.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dog.257.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename  category\n",
              "0  dog.142.jpg         1\n",
              "1  dog.638.jpg         1\n",
              "2  dog.907.jpg         1\n",
              "3  dog.485.jpg         1\n",
              "4  dog.257.jpg         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "72bf69e817f67f5a2eaff8561217e22077248553",
        "id": "ki1aAP7KZrta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e1199491-9fc4-4e6d-d9e9-5f11e36983f7"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>cat.527.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>cat.0.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>cat.849.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>cat.72.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>cat.427.jpg</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         filename  category\n",
              "1995  cat.527.jpg         0\n",
              "1996    cat.0.jpg         0\n",
              "1997  cat.849.jpg         0\n",
              "1998   cat.72.jpg         0\n",
              "1999  cat.427.jpg         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "a999484fc35b73373fafe2253ae9db7ff46fdb90",
        "id": "2nOmq03yZrtf",
        "colab_type": "text"
      },
      "source": [
        "### See Total In count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "fa26f0bc7a6d835a24989790b20f3c6f32946f45",
        "id": "Qn3dkVCQZrtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "8d8d984e-5b0b-4549-811d-87569cf3069c"
      },
      "source": [
        "df['category'].value_counts().plot.bar()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2668db0b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD1CAYAAAC87SVQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "3a08da58107777a1dd05c4a4bf5c484484923cac",
        "id": "sSaQsnj-Zrtl",
        "colab_type": "text"
      },
      "source": [
        "From our data we have 12000 cats and 12000 dogs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "400a293df3c8499059d9175f3915187074efd971",
        "id": "nvVEOwGyZrtn",
        "colab_type": "text"
      },
      "source": [
        "# See sample image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "602b40f7353871cb161c60b5237f0da0096b2f47",
        "id": "KLxQVMYpZrtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample = random.choice(filenames)\n",
        "image = load_img(\"../input/train/train/\"+sample)\n",
        "plt.imshow(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b244e6b7715a04fc6df92dd6dfa3d35c473ca600",
        "id": "MLmPLseCZrtu",
        "colab_type": "text"
      },
      "source": [
        "# Build Model\n",
        "\n",
        "<img src=\"https://i.imgur.com/ebkMGGu.jpg\" width=\"100%\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN4WwGLNZrtv",
        "colab_type": "text"
      },
      "source": [
        "* **Input Layer**: It represent input image data. It will reshape image into single diminsion array. Example your image is 64x64 = 4096, it will convert to (4096,1) array.\n",
        "* **Conv Layer**: This layer will extract features from image.\n",
        "* **Pooling Layer**: This layerreduce the spatial volume of input image after convolution.\n",
        "* **Fully Connected Layer**: It connect the network from a layer to another layer\n",
        "* **Output Layer**: It is the predicted values layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "8c9f833c1441b657c779844912d0b8028218d454",
        "id": "NH0EP8tMZrty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "bd496f6c65888a969be3703135b0b03a8a1190c8",
        "id": "tlD2fvTrZrt2",
        "colab_type": "text"
      },
      "source": [
        "# Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "9aa032f0f6da539d23918890d2d131cc3aac8c7a",
        "id": "iQyED2vHZrt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "76c9ba4fb7f930c96b2c3e0d6b68ed9fa6a4227b",
        "id": "1bnY4kqCZrt8",
        "colab_type": "text"
      },
      "source": [
        "**Early Stop**\n",
        "\n",
        "To prevent over fitting we will stop the learning after 10 epochs and val_loss value not decreased"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "3421c5ec428da6c0d8cc1184179a9caff1e01d1c",
        "id": "97nI6sdGZrt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "earlystop = EarlyStopping(patience=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "51d3fe52e911286433cedf6e47332948a253361e",
        "id": "eD_jyVKwZruB",
        "colab_type": "text"
      },
      "source": [
        "**Learning Rate Reduction**\n",
        "\n",
        "We will reduce the learning rate when then accuracy not increase for 2 steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "8010a5661ad8924d2db24af0f3c00b1593b38901",
        "id": "ph1dCRBXZruC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "a79cc604199469789f183096d863f7248e5f6aab",
        "id": "H_tveEnHZruH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [earlystop, learning_rate_reduction]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZciBNtSZruL",
        "colab_type": "text"
      },
      "source": [
        "# Prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bME16bZTZruM",
        "colab_type": "text"
      },
      "source": [
        "Because we will use image genaretor `with class_mode=\"categorical\"`. We need to convert column category into string. Then imagenerator will convert it one-hot encoding which is good for our classification. \n",
        "\n",
        "So we will convert 1 to dog and 0 to cat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VOqYfyTiZruO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'}) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "4eeb7af8dcf02c4ef5ca744c8305c51a2f5cedef",
        "id": "xHLH38okZruS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df, validate_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "validate_df = validate_df.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "b84836337441705eda9d2e655665ffa14d9feead",
        "id": "p1OJflTQZruW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df['category'].value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "19cf03f9a3c39532d6e2d06bd30be49a5afd9d57",
        "id": "BjWnde7SZruZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validate_df['category'].value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "ae3dec0361f0443132d0309d3b883ee80070cf9f",
        "id": "OKY69frvZrud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_train = train_df.shape[0]\n",
        "total_validate = validate_df.shape[0]\n",
        "batch_size=15"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ff760be9104f7d9492467b8d9d3405011aa77d11",
        "id": "Wqv-l-DvZruh",
        "colab_type": "text"
      },
      "source": [
        "# Traning Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "4d1c7818703a8a4bac5c036fdea45972aa9e5e9e",
        "id": "V4l7y5QuZrui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    rescale=1./255,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df, \n",
        "    \"../input/train/train/\", \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "859c7b2857939c19fd2e3bb32839c9f7deb5aa3f",
        "id": "Z--l554oZruk",
        "colab_type": "text"
      },
      "source": [
        "### Validation Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "7925e16bcacc89f4484fb6fe47e54d6420af732e",
        "id": "9HbrNSOZZrum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df, \n",
        "    \"../input/train/train/\", \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "6e17fc1f002fedd60febb78fee5e81770640b909",
        "id": "gsdYp1WkZrup",
        "colab_type": "text"
      },
      "source": [
        "# See how our generator work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "4252cce168ab65f88e44a8ebc2672607bc852af4",
        "id": "EyB_2sK-Zruq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_df = train_df.sample(n=1).reset_index(drop=True)\n",
        "example_generator = train_datagen.flow_from_dataframe(\n",
        "    example_df, \n",
        "    \"../input/train/train/\", \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "23d923dba747f8b47dc75569244cecc6f70df321",
        "id": "GVrrqd3RZrut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "for i in range(0, 15):\n",
        "    plt.subplot(5, 3, i+1)\n",
        "    for X_batch, Y_batch in example_generator:\n",
        "        image = X_batch[0]\n",
        "        plt.imshow(image)\n",
        "        break\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "810ddf1373d9db470ed48da4f30ca5a6c1274435",
        "id": "QmSNOqRnZruy",
        "colab_type": "text"
      },
      "source": [
        "Seem to be nice "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "5cd8df64e794ed17de326b613a9819e7da977a0e",
        "id": "381teqlHZruz",
        "colab_type": "text"
      },
      "source": [
        "# Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "0836a4cc8aa0abf603e0f96573c0c4ff383ad56b",
        "id": "NOEU04xPZru0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=3 if FAST_RUN else 50\n",
        "history = model.fit_generator(\n",
        "    train_generator, \n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//batch_size,\n",
        "    steps_per_epoch=total_train//batch_size,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "aa1fbc4081ae0de2993188b2bf658a0be5bc0687",
        "id": "iZFFJO9TZru4",
        "colab_type": "text"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "67575a4decdaf79a915d23151626b784ffa82642",
        "id": "DLPOXjwdZru5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "1b76c0a9040bc0babf0a453e567e41e22f8a1e0e",
        "id": "rV2ZpztHZru9",
        "colab_type": "text"
      },
      "source": [
        "# Virtualize Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "79055f2dc3e2abb47bea758e0464c86ca42ab431",
        "id": "5hZAxtsSZru-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
        "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
        "ax1.set_xticks(np.arange(1, epochs, 1))\n",
        "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
        "\n",
        "ax2.plot(history.history['acc'], color='b', label=\"Training accuracy\")\n",
        "ax2.plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\n",
        "ax2.set_xticks(np.arange(1, epochs, 1))\n",
        "\n",
        "legend = plt.legend(loc='best', shadow=True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "764dc66e4b2bc558f3a0f90b80bb802f5b3d45a8",
        "id": "6QR3WNjUZrvB",
        "colab_type": "text"
      },
      "source": [
        "# Prepare Testing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "c35e70d3e1e4834dbbf840fa0ea08c049bfcd915",
        "id": "bQmK2EkIZrvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_filenames = os.listdir(\"../input/test1/test1\")\n",
        "test_df = pd.DataFrame({\n",
        "    'filename': test_filenames\n",
        "})\n",
        "nb_samples = test_df.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "291bc3996dce8d05e174b27d64f03996d3e8038e",
        "id": "spJ6Yp12ZrvE",
        "colab_type": "text"
      },
      "source": [
        "# Create Testing Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "52249ec1c35fb1be3adef386be245de3794e55aa",
        "id": "11dcX0AiZrvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_gen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_gen.flow_from_dataframe(\n",
        "    test_df, \n",
        "    \"../input/test1/test1/\", \n",
        "    x_col='filename',\n",
        "    y_col=None,\n",
        "    class_mode=None,\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "2fa580afca2931ec5ce374e732d8c1789d03f2ed",
        "id": "uxApJ3cyZrvI",
        "colab_type": "text"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "4782eb23fa7d003f0e2415d995894017edb2d896",
        "id": "iM3Yx7dtZrvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "So2nebhlZrvL",
        "colab_type": "text"
      },
      "source": [
        "For categoral classication the prediction will come with probability of each category. So we will pick the category that have the highest probability with numpy average max"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "u4nYIfeDZrvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['category'] = np.argmax(predict, axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S2Y9J3lZrvZ",
        "colab_type": "text"
      },
      "source": [
        "We will convert the predict category back into our generator classes by using `train_generator.class_indices`. It is the classes that image generator map while converting data into computer vision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_JtC5NiAZrvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_map = dict((v,k) for k,v in train_generator.class_indices.items())\n",
        "test_df['category'] = test_df['category'].replace(label_map)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diEfg_fUZrvd",
        "colab_type": "text"
      },
      "source": [
        "From our prepare data part. We map data with `{1: 'dog', 0: 'cat'}`. Now we will map the result back to dog is 1 and cat is 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OQ-131U5Zrve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['category'] = test_df['category'].replace({ 'dog': 1, 'cat': 0 })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "b00add65fe765529e637c3a9904d710bb7eff1d8",
        "id": "uzfXh2wzZrvh",
        "colab_type": "text"
      },
      "source": [
        "### Virtaulize Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "d0bf6dd5ff344092fa0121f70bdd60fa5a40e29c",
        "id": "B5pESVI8Zrvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df['category'].value_counts().plot.bar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "ce72a83f80d6e012b12b82c8ee3365d671a3b307",
        "id": "-C84XxcSZrvj",
        "colab_type": "text"
      },
      "source": [
        "### See predicted result with images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "98b41dc83075e6297137fb45bf703c313dd4ae28",
        "id": "jhhfZLJuZrvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_test = test_df.head(18)\n",
        "sample_test.head()\n",
        "plt.figure(figsize=(12, 24))\n",
        "for index, row in sample_test.iterrows():\n",
        "    filename = row['filename']\n",
        "    category = row['category']\n",
        "    img = load_img(\"../input/test1/test1/\"+filename, target_size=IMAGE_SIZE)\n",
        "    plt.subplot(6, 3, index+1)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' )\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "d1ca25943e73aa20a37f9fb8670ee430caeaaf1f",
        "id": "F4T2uIMfZrvn",
        "colab_type": "text"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "_uuid": "cce9f3e2ffff0693d79d84590ed71fbbca7c3c7c",
        "id": "8kIh2NJgZrvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission_df = test_df.copy()\n",
        "submission_df['id'] = submission_df['filename'].str.split('.').str[0]\n",
        "submission_df['label'] = submission_df['category']\n",
        "submission_df.drop(['filename', 'category'], axis=1, inplace=True)\n",
        "submission_df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}